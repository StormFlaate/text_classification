{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6eb4f19",
   "metadata": {},
   "source": [
    "# Section 0: Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a60e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data science\n",
    "import numpy as np\n",
    "\n",
    "# helper functions\n",
    "from helper_func_and_classes import TwitterDataset_BERT\n",
    "from helper_func_and_classes import create_data_loader_BERT\n",
    "from helper_func_and_classes import split_dataset\n",
    "from helper_func_and_classes import create_dataset_list\n",
    "from helper_func_and_classes import output_numpy_array_from_model_training\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ffd9ea",
   "metadata": {},
   "source": [
    "\n",
    "# Section 1: Data preprocessing section\n",
    "## Section 1.1: Creating lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870378cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all_data_lite:  200000\n",
      "Length of all_labels_lite:  200000 \n",
      "\n",
      "Length of all_data_full:  2500000\n",
      "Length of all_labels_full:  2500000 \n",
      "\n",
      "Length of submission_data:  10000\n"
     ]
    }
   ],
   "source": [
    "pos_data_full = create_dataset_list(\"./twitter-datasets/train_pos_full.txt\")\n",
    "pos_labels_full = [1]*len(pos_data_full)\n",
    "\n",
    "neg_data_full = create_dataset_list(\"./twitter-datasets/train_neg_full.txt\")\n",
    "neg_labels_full = [0]*len(neg_data_full)\n",
    "\n",
    "all_data_full = pos_data_full + neg_data_full\n",
    "all_labels_full = pos_labels_full + neg_labels_full\n",
    "\n",
    "\n",
    "pos_data_lite = create_dataset_list(\"./twitter-datasets/train_pos.txt\")\n",
    "pos_labels_lite = [1]*len(pos_data_lite)\n",
    "\n",
    "neg_data_lite = create_dataset_list(\"./twitter-datasets/train_neg.txt\")\n",
    "neg_labels_lite = [0]*len(neg_data_lite)\n",
    "\n",
    "all_data_lite = pos_data_lite + neg_data_lite\n",
    "all_labels_lite = pos_labels_lite + neg_labels_lite\n",
    "\n",
    "\n",
    "submission_data = create_dataset_list(\"./twitter-datasets/test_data.txt\")\n",
    "\n",
    "\n",
    "print(\"Length of all_data_lite: \", len(all_data_lite))\n",
    "print(\"Length of all_labels_lite: \", len(all_labels_lite), \"\\n\")\n",
    "print(\"Length of all_data_full: \", len(all_data_full))\n",
    "print(\"Length of all_labels_full: \", len(all_labels_full), \"\\n\")\n",
    "\n",
    "\n",
    "print(\"Length of submission_data: \",len(submission_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bf9f28",
   "metadata": {},
   "source": [
    "## Section 1.2: Sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe306f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "max_length = 37\n",
    "batch_size = 256\n",
    "DATA_FULL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e010736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRETRAINED_MODEL_BERT = 'bert-base-cased'\n",
    "PRETRAINED_MODEL_BERT = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686fcd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(pos_data_lite[0])\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0ece29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/fritt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "    pos_data_lite[0],\n",
    "    max_length=37,\n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dadb768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_FULL:\n",
    "    train_samples_lite, test_samples_lite, train_labels_lite, test_labels_lite = train_test_split(\n",
    "        all_data_lite, \n",
    "        all_labels_lite, \n",
    "        test_size=0.1, \n",
    "        random_state=RANDOM_SEED)\n",
    "    \n",
    "if DATA_FULL:\n",
    "    train_data_samples_full, test_data_samples_full, train_data_labels_full, test_data_labels_full = train_test_split(\n",
    "        all_data_full, \n",
    "        all_labels_full, \n",
    "        test_size=0.1, \n",
    "        random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2d9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_FULL:\n",
    "    train_loader_lite = create_data_loader_BERT(\n",
    "        train_samples_lite,\n",
    "        train_labels_lite,\n",
    "        tokenizer, \n",
    "        max_length, \n",
    "        batch_size)\n",
    "\n",
    "    test_loader_lite = create_data_loader_BERT(\n",
    "        test_samples_lite,\n",
    "        test_labels_lite,\n",
    "        tokenizer, \n",
    "        max_length, \n",
    "        batch_size)\n",
    "\n",
    "if DATA_FULL:\n",
    "    train_loader_full = create_data_loader_BERT(\n",
    "        train_samples_full,\n",
    "        train_labels_full,\n",
    "        tokenizer, \n",
    "        max_length, \n",
    "        batch_size)\n",
    "\n",
    "    test_loader_full = create_data_loader_BERT(\n",
    "        test_samples_full,\n",
    "        test_labels_full,\n",
    "        tokenizer, \n",
    "        max_length, \n",
    "        batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f27873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_bert = BertModel.from_pretrained(PRETRAINED_MODEL_BERT, return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797248d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = model_bert(\n",
    "    input_ids=encoding['input_ids'],\n",
    "    attention_mask=encoding['attention_mask']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eedaada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRETRAINED_MODEL_BERT, return_dict=False)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb27772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c2901",
   "metadata": {},
   "source": [
    "### Parameters to tune:\n",
    "Batch size: 16, 32  \n",
    "Learning rate (Adam): 5e-5, 3e-5, 2e-5  \n",
    "Number of epochs: 2, 3, 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3024539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCHS = 3\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_loader_lite) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d9d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"]\n",
    "        attention_mask = d[\"attention_mask\"]\n",
    "        labels = d[\"labels\"]\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        correct_predictions += torch.sum(predicted == labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38af0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"]\n",
    "            attention_mask = d[\"attention_mask\"]\n",
    "            labels = d[\"labels\"]\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            correct_predictions += torch.sum(predicted == labels)\n",
    "            losses.append(loss.item())\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "302836a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 0/704 [00:00<?, ?it/s]/Users/fritt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/fritt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  1%|â–Ž                          | 9/704 [09:40<12:26:58, 64.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pc/5ytjzw0165n86jc4_pv2802c0000gn/T/ipykernel_82788/172252148.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch: \" epoch)\n",
    "    train_accuracy, loss = train_epoch(\n",
    "        model,\n",
    "        train_loader_lite,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        len(train_samples_lite)\n",
    "      )\n",
    "\n",
    "    print(f'Train loss {loss} accuracy {train_accuracy}')\n",
    "    test_accuracy, test_loss = eval_model(\n",
    "        model,\n",
    "        test_loader_lite,\n",
    "        loss_fn,\n",
    "        len(test_samples_lite)\n",
    "      )\n",
    "    print(f'Test loss {test_loss} accuracy {test_accuracy}')\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ad5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
